# String.intern()导致YGC越来越久

## 问题背景


2018年7月某服务上线后运行平稳，但监控系统发现其YGC时间越来越久，直至发生一次FGC后有所缓解，后重复发生上述过程，GC整体情况无OOM表象


## 问题初步排查与猜测

分析该问题的现象，YGC的整个过程是正常的，没有出现OOM一样的内存逐渐上涨现象。因此不是像并发包LinkedBlockingQueue那个问题一样，是有对象使用掉了Y区堆大小导致的标记、复制时间增强。但是YGC又确实在增加，是什么东西导致了YGC收集正常，却会越来越久。尝试过内存dump、线程dump、JVM现象观察、操作系统各项资源监控等等各种常规手段，但是基本都看不出什么问题。

翻阅了相关资料后，猜测与String Table使用有关。此时只能逐项猜想论证排查的方式

## 证实猜想

使用了以下工具类打印String Table的长度：

```java
public class PrintStringTable extends Tool {
    public PrintStringTable() {
    }
    public static void main(String args[]) throws Exception {
        if (args.length == 0 || args.length > 1) {
            System.err.println("Usage: java PrintStringTable <PID of the JVM whose string table you want to print>");
            System.exit(1);
        }
        PrintStringTable pst = new PrintStringTable();
        pst.execute(args);
        pst.stop();
    }
    @Override
    public void run() {
        StringTable table = VM.getVM().getStringTable();
        table.stringsDo(new StringPrinter());
    }
    class StringPrinter implements StringTable.StringVisitor {
        private final OopField stringValueField;
        public StringPrinter() {
            InstanceKlass strKlass = SystemDictionary.getStringKlass();
            stringValueField = (OopField) strKlass.findField("value", "[C");
        }
        @Override
        public void visit(Instance instance) {
            TypeArray charArray = ((TypeArray) stringValueField.getValue(instance));
            StringBuilder sb = new StringBuilder();
            for (long i = 0; i < charArray.getLength(); i++) {
                sb.append(charArray.getCharAt(i));
            }
            System.out.println("Address: " + instance.getHandle() + " Content: " + sb.toString());
        }
    }
}
```

期间保持系统高压力运行一段时间后，发现String Table可以打出200多W行

![string table情况](/img/string_table.png)

其中打印出来的Content，是业务的一些key值。基本可以确定是String Table使用导致的YGCT越来越久，详细了解了下String Table的作用，是为了节约String对象的创建资源开销，以指针的方式将不同的对象指向同一片内存区域。YGC会扫描这块位于old区的空间，所以YGC无法回收。只能等FGC才可以回收。

那么是什么导致了String Table的使用，并且用了200多W个数据。

因为是jdk内方法的调用，所以打印堆栈一定可以找到调用方，用不断循环收集结合grep的方式找到了以下堆栈调用

- **string Table的使用方 某中间件系统**
![string table使用方](/img/线程dump.png)

至此，我们通过猜测造成问题可能发生的原因、不断收集线程dump的基本定位到了问题。接下来是找出问题的使用者

## 问题解决

接下来就是了解该中间件系统为什么要这么做。
原来是中间件认为调用该方法的key应该是一些固定的值，而在我们系统中key是不断变化的商品型号id，所以每个id都会在string Table中创建一块区域，集合由于String Table只被YGC扫描，不被YGC收集的特点，最终导致了YGC越来越久需要FGC才能缓解。

于是我们优化了该场景的使用，改为依旧使用普通的String对象创建，解决了问题。

## 总结回顾

- **本文总体阐述了一个线上服务在上线后YGCT不断增加的问题**
- **通过基本的判断得出了YGC无法收集、存在于old区，YGC却需要扫描的特性**
- **结合得出的特性和文献的搜索，得到了怀疑对象：String Table**
- **以日志打印的手段打印String Table的大小**
- **得到确定的结论后以线程dump的手段找到使用方**
- **与开发者沟通了解使用的原因，进行业务场景的优化**

